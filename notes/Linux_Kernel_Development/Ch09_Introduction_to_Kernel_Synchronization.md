# Chapter 9: [An Introduction to Kernel Synchronization]

## **Summary**
- ### **Introduction**
	- **Need**: Protect shared resources from concurrent access in kernel to prevent data corruption.
	- **Issue**: Multiple threads (e.g., on SMP systems) or preemption can access data simultaneously.
	- **History**: Pre-2.0 kernels had simpler concurrency (single CPU, interrupts only); 2.0 added SMP, 2.6 added preemption.
	- **Challenge**: Kernel code on multiple processors or preempted tasks can cause race conditions.
	- **Solution**: Synchronization ensures safe access to shared data (details in Chapter 10).

- ### Critical Regions and Race Conditions
	- **Definition**: Critical regions are code accessing shared data; concurrent access causes race conditions.
	- **Goal**: Execute critical regions atomically (uninterrupted) to prevent data inconsistencies.
	- #### Why Do We Need Protection?
		- **Problem**: Race conditions occur when multiple threads access shared data simultaneously.
		- **Example**: ATM withdrawals from same account; concurrent transactions can miscalculate funds.
		- **Solution**: Make transactions atomic (indivisible) with locking to ensure correct execution.
		- **Impact**: Without protection, data errors (e.g., wrong account balance) occur, hard to debug.
	- #### The Single Variable
		- **Example**: Incrementing a shared integer (`i++`) can fail if two threads interleave.
		- **Issue**: Threads may read same initial value (e.g., 7), increment to 8, overwrite, losing one increment.
		- **Solution**: Use atomic instructions (read, increment, write in one step) to ensure correct result (e.g., 9).
		- **Kernel Support**: Provides atomic interfaces (in Chapter 10) for indivisible operations.

- ### Locking
	- **Purpose**: Locks ensure only one thread accesses shared data, preventing race conditions.
	- **Example**: Queue manipulation (add/remove requests) risks corruption without locks.
	- **Mechanism**: Lock acts like a door; only one thread holds it, others wait.
	- **Operation**: Thread acquires lock, accesses data, releases lock; others wait if locked.
	- **Implementation**: Uses atomic instructions (e.g., x86’s compare-and-exchange) to avoid races in locking.
	- **Types**: Different locks vary (e.g., busy-wait vs. sleep), covered in Chapter 10.
	- **Note**: Locks are voluntary; code must use them to protect shared data.
	- #### Causes of Concurrency
		- **Sources in Kernel**:
			- Interrupts: Can interrupt code at any time, accessing shared data.
			- Softirqs/Tasklets: Run asynchronously, may access same data.
			- Kernel Preemption: Scheduler can switch tasks, causing data access overlap.
			- Sleeping: Task sleep invokes scheduler, allowing other tasks to access data.
			- SMP: Multiple processors run kernel code simultaneously, accessing shared data.
		- **Types**: Pseudo-concurrency (interleaved execution) and true concurrency (simultaneous on SMP).
		- **Impact**: All sources can cause race conditions, requiring synchronization.
		- **Design**: Locking must be planned early to handle all concurrency scenarios.
	- #### Knowing What to Protect
		- **What Needs Locking**: Global/shared data accessible by multiple threads (e.g., kernel structures).
		- **What Doesn’t**: Local variables (stack-based) or data exclusive to one task.
		- **Safety Terms**:
			- **Interrupt-safe:** Protects data from interrupt handler access.
			- **SMP-safe:** Protects data from concurrent processor access.
			- **Preempt-safe:** Protects data from preemption by scheduler.
		- **CONFIG Options**: `CONFIG_SMP` and `CONFIG_PREEMPT` enable/disable SMP/preemption support, reducing locking overhead on uniprocessor systems.
		- **Questions to Ask**:
			- Is data global/shared? Can other threads, interrupts, or processors access it?
			- Can preemption or sleep affect shared data? What prevents data freeing?
			- How to ensure concurrency safety?
		- **Rule**: Lock data, not code, for all shared resources.

- ### Deadlocks
	- **Definition**: Deadlock occurs when threads wait for resources held by each other, preventing progress.
	- **Examples**:
		- Self-deadlock: Thread tries to acquire lock it already holds, waits forever.
		- ABBA Deadlock: Two threads each hold one lock (A, B) and wait for the other’s lock.
	- **Prevention Rules**:
		- Use lock ordering: Always acquire nested locks in same order (e.g., cat, dog, fox).
		- Avoid starvation: Ensure code completes, no indefinite waiting.
		- Don’t double-acquire same lock.
		- Keep locking simple to minimize deadlock risk.
	- **Lock Ordering**: Critical to prevent deadlocks; document order in comments.
	- **Unlocking**: Order doesn’t affect deadlocks, but inverse order is common.
	- **Debugging**: Linux kernel has tools to detect deadlocks (covered in Chapter 10).
	- **Example**: Thread 1 (cat, dog, fox locks) and Thread 2 (fox, dog) deadlock if order not followed.

- ### Contention and Scalability
	- **Lock Contention**: When a lock is held and other threads wait, slowing performance.
	- **Causes**: Frequent lock acquisition or long hold times increase contention.
	- **Scalability**: System’s ability to perform well with more processes, processors, or memory.
	- **Lock Granularity**:
		- Coarse: Locks large data (e.g., entire subsystem), poor scalability under contention.
		- Fine: Locks small data (e.g., single element), reduces contention but adds overhead.
	- **Linux Evolution**: From single lock (2.0) to fine-grained locks (2.6), e.g., per-processor runqueues.
	- **Trade-off**: Fine-grained locking improves SMP scalability but may add overhead on smaller systems.
	- **Design Principle**: Start with simple locking, refine to finer granularity only if contention occurs.
	- **Example**: Single lock for linked list vs. per-node locks; balance contention vs. overhead.

## **Quick Recall**
- **Q: Why is synchronization needed in the kernel?**
	- **A**: Protects shared data from concurrent access by multiple threads or processors, preventing race conditions.
- **Q: What is a critical region?**
	- **A**: Code accessing shared data that must execute atomically to avoid race conditions.
- **Q: What causes concurrency in the kernel?**
	- **A**: Interrupts, softirqs/tasklets, preemption, sleeping tasks, and SMP (multiple processors).
- **Q: What is a deadlock?**
	- **A**: Threads wait for resources held by each other, causing all to stall (e.g., ABBA deadlock).
- **Q: How to prevent deadlocks?**
	- **A**: Use consistent lock ordering, avoid starvation, don’t double-acquire locks, keep locking simple.
- **Q: What is lock contention?**
	- **A**: When threads wait for a held lock, reducing performance; high contention from frequent or long-held locks.
- **Q: How does lock granularity affect scalability?**
	- **A**: Coarse locks limit scalability; fine-grained locks improve SMP performance but add overhead.

## **Hands-on Ideas**
- **GPIO Shared Data Test**:
    - Write BBB kernel module with GPIO interrupt incrementing a global counter.
    - Access counter from two kernel threads without locking; observe race conditions.
    - Add spinlock to protect counter, verify correct increments.
    - **Learn**: Race conditions, need for locking.
- **Lock Ordering Experiment**:
    - Create BBB module with two GPIO interrupts using two spinlocks (A, B).
    - Test ABBA deadlock by acquiring locks in opposite orders; monitor hangs.
    - Fix with consistent lock order (e.g., always A then B).
    - **Learn**: Deadlock prevention, lock ordering.
- **Contention Measurement**:
	- Write BBB module with a global linked list, protected by one spinlock.
	- Simulate high contention with multiple kernel threads accessing list.
	- Measure latency using `ktime_get()`; split into per-node locks, compare performance.
	- **Learn**: Lock contention, granularity impact.
- **Interrupt-Safe Locking**:
	- Develop BBB module where GPIO interrupt and process context share a counter.
	- Use `spin_lock_irqsave()` to protect counter; test with frequent interrupts.
	- Verify counter consistency via `/proc `file.
	- **Learn**: Interrupt-safe synchronization, SMP safety.